{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of Palladium Spot Price\n",
    "\n",
    "Data is provided free for non-commercial use by Perth Mint (www.perthmint.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Task\n",
    "\n",
    "Extract-Load-Transform (ELT) process of transforming noisy data in CSV files (e.g. inconsistent data types, spurious values, etc.) into cleaned data suitable for increasingly sophisticated analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import locale\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "# CONSTANTS\n",
    "DATE_LINE_RE = re.compile('^\"?\\d+')\n",
    "DATE_FORM_RE = re.compile('^\"?(\\d+)/(\\d+)/(\\d+)\"?\\s*(.*)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function ensures pandas will not throw exceptions without a good reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locale_string_to_float(value: str) -> float:\n",
    "    \"\"\"Attempt to convert the argument to a float.\"\"\"\n",
    "    \n",
    "    returnVal = np.nan\n",
    "    try:\n",
    "        returnVal = locale.atof(value)\n",
    "    except ValueError as error:\n",
    "        pass\n",
    "    \n",
    "    return returnVal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A specific problem with the CSV files occurs when dates cross from the 10th to the 11th of some months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(filename: str, after_millenium: bool) -> None:\n",
    "    \"\"\"Create a new CSV file from ISO-correct dates.\"\"\"\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8') as infile:\n",
    "        old_date = datetime(1900, 1, 1)\n",
    "        millenium_crossed = after_millenium\n",
    "        with open(filename + '.cleaned.csv', 'w', encoding='utf-8') as outfile:\n",
    "            for line in infile:\n",
    "                if DATE_LINE_RE.match(line):\n",
    "                    line = line.strip()\n",
    "                    matched = DATE_FORM_RE.match(line)\n",
    "                    if matched:\n",
    "                        year_str = matched[3]\n",
    "                        if not millenium_crossed:\n",
    "                            if year_str == '00':\n",
    "                                millenium_crossed = True\n",
    "                            else:\n",
    "                                year_str = f\"19{year_str}\"\n",
    "                                \n",
    "                        if millenium_crossed:\n",
    "                            year_str = f\"20{year_str}\"\n",
    "                            \n",
    "                        maybe_month = matched[2]\n",
    "                        maybe_day = matched[1]\n",
    "                        current_date = parse(\n",
    "                            f\"{maybe_day}/{maybe_month}/{year_str}\"\n",
    "                        )\n",
    "                        if abs((current_date - old_date).days) > 1:\n",
    "                            current_date = parse(\n",
    "                                f\"{maybe_month}/{maybe_day}/{year_str}\"\n",
    "                            )\n",
    "                        print(\n",
    "                            f\"{current_date}{matched[4]}\",\n",
    "                            file=outfile\n",
    "                        )\n",
    "                        old_date = current_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to remove outliers in a given pandas dataframe. The valid column name is given as well as a floating point threshold factor. All rows with values too far above or below the threshold are returned as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abnormal_value_indices(df: pd.DataFrame, column_name: str, threshold_factor: float) -> list:\n",
    "    \"\"\"Returns rows in a dataframe exceeding a threshold.\"\"\"\n",
    "    \n",
    "    abnormals_list = []\n",
    "    previous_value = df[column_name][0]\n",
    "    for i in range(1, len(df[column_name])):\n",
    "        current_value = df[column_name][i]\n",
    "        if (previous_value > current_value * threshold_factor) or (current_value > previous_value * threshold_factor):\n",
    "            abnormals_list.append(df.index[i])\n",
    "        else:\n",
    "            previous_value = current_value\n",
    "    print(abnormals_list)\n",
    "    \n",
    "    return(abnormals_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create CSV files filled with clean (albeit sparse) data based on the original CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data(r'Data\\part_1.csv', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data(r'Data\\part_2.csv', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is split between the 2 CSV files. There are prices from 1968 to 2015 in one, and from 2016 onwards in the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_fixes_daily_1968_2015 = pd.read_csv(\n",
    "    r'Data\\part_1.csv.cleaned.csv',\n",
    "    encoding='utf-8',\n",
    "    header=None,\n",
    "    names=['Date', 'Au AM', 'Au PM', 'Ag', 'Pt AM', 'Pt PM', 'Pd AM', 'Pd PM'],\n",
    "    index_col=0, \n",
    "    skiprows=[0,1,2,3,4],\n",
    "    usecols=[0,1,2,3,4,5,6,7],\n",
    "    parse_dates=True,\n",
    "    converters={\n",
    "        1: locale_string_to_float,\n",
    "        2: locale_string_to_float,\n",
    "        3: locale_string_to_float,\n",
    "        4: locale_string_to_float,\n",
    "        5: locale_string_to_float,\n",
    "        6: locale_string_to_float,\n",
    "        7: locale_string_to_float\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe deliberately holds NaN values as compaction will be done just before the data is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_fixes_daily_1968_2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_fixes_daily_from_2016_on = pd.read_csv(\n",
    "    r'Data\\part_2.csv.cleaned.csv',\n",
    "    encoding='utf-8',\n",
    "    header=None,\n",
    "    names=['Date', 'Au AM', 'Au PM', 'Ag', 'Pt AM', 'Pt PM', 'Pd AM', 'Pd PM'],\n",
    "    index_col=0,\n",
    "    skiprows=[0,1,2,3,4],\n",
    "    usecols=[0,1,2,3,4,5,6,7],\n",
    "    parse_dates=True,\n",
    "    converters={\n",
    "        1: locale_string_to_float,\n",
    "        2: locale_string_to_float,\n",
    "        3: locale_string_to_float,\n",
    "        4: locale_string_to_float,\n",
    "        5: locale_string_to_float,\n",
    "        6: locale_string_to_float,\n",
    "        7: locale_string_to_float\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_fixes_daily_from_2016_on.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ready for basic analysis, we drop NaN entries in specific columns and then drop outliers. Here the outliers are values that are bigger or smaller than their preceding value by some factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d1 = {\n",
    "    'Pd AM': df_london_fixes_daily_1968_2015['Pd AM'],\n",
    "    'Pd PM': df_london_fixes_daily_1968_2015['Pd PM']\n",
    "}\n",
    "df_palladium_1 = pd.DataFrame(data_d1).dropna(axis=0)\n",
    "df_palladium_1 = df_palladium_1.drop(abnormal_value_indices(df_palladium_1, 'Pd AM', 1.5))\n",
    "df_palladium_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d2 = {\n",
    "    'Pd AM': df_london_fixes_daily_from_2016_on['Pd AM'],\n",
    "    'Pd PM': df_london_fixes_daily_from_2016_on['Pd PM']\n",
    "}\n",
    "df_palladium_2 = pd.DataFrame(data_d2).dropna(axis=0)\n",
    "df_palladium_2 = df_palladium_2.drop(abnormal_value_indices(df_palladium_2, 'Pd AM', 1.5))\n",
    "df_palladium_2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the compacted dataframes to analyze the data contiguously from 1968 to 2016 onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_palladium = df_palladium_1.append(df_palladium_2)\n",
    "df_palladium.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(df_palladium['Pd AM'])\n",
    "ax.grid()\n",
    "fig.set_size_inches(15, 5)\n",
    "plt.title(\"Historical Daily Palladium Spot Prices (AM)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price / USD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix\n",
    "\n",
    "Visualizations to see the data transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_fixes_daily_1968_2015_raw = pd.read_csv(\n",
    "    r'Data\\part_1.csv', \n",
    "    encoding='utf-8',\n",
    "    header=None,\n",
    "    names=['Date', 'Au AM', 'Au PM', 'Ag', 'Pt AM', 'Pt PM', 'Pd AM', 'Pd PM'],\n",
    "    index_col=0, \n",
    "    skiprows=[0,1,2,3,4],\n",
    "    usecols=[0,1,2,3,4,5,6,7],\n",
    "    parse_dates=True,\n",
    "    converters={\n",
    "        1: locale_string_to_float,\n",
    "        2: locale_string_to_float,\n",
    "        3: locale_string_to_float,\n",
    "        4: locale_string_to_float,\n",
    "        5: locale_string_to_float,\n",
    "        6: locale_string_to_float,\n",
    "        7: locale_string_to_float\n",
    "    }\n",
    ")\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(df_london_fixes_daily_1968_2015_raw['Pd AM'])\n",
    "ax.grid()\n",
    "fig.set_size_inches(15, 5)\n",
    "plt.title(\"Palladium Spot Price (AM) - Raw Data (part_1.csv) [1968-2015]\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price / USD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_london_fixes_daily_2016_on_raw = pd.read_csv(\n",
    "    r'Data\\part_2.csv', \n",
    "    encoding='utf-8',\n",
    "    header=None,\n",
    "    names=['Date', 'Au AM', 'Au PM', 'Ag', 'Pt AM', 'Pt PM', 'Pd AM', 'Pd PM'],\n",
    "    index_col=0, \n",
    "    skiprows=[0,1,2,3,4],\n",
    "    usecols=[0,1,2,3,4,5,6,7],\n",
    "    parse_dates=True,\n",
    "    converters={\n",
    "        1: locale_string_to_float,\n",
    "        2: locale_string_to_float,\n",
    "        3: locale_string_to_float,\n",
    "        4: locale_string_to_float,\n",
    "        5: locale_string_to_float,\n",
    "        6: locale_string_to_float,\n",
    "        7: locale_string_to_float\n",
    "    }\n",
    ")\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(df_london_fixes_daily_2016_on_raw['Pd AM'])\n",
    "ax.grid()\n",
    "fig.set_size_inches(15, 5)\n",
    "plt.title(\"Palladium Spot Price (AM) - Raw Data (part_2.csv) [2016+]\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price / USD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Initial data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(df_london_fixes_daily_1968_2015['Pd AM'])\n",
    "ax.grid()\n",
    "fig.set_size_inches(15, 5)\n",
    "plt.title(\"Palladium Spot Price (AM) - Initial Clean Data (part_1.csv.cleaned.csv) [1968-2015]\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price / USD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 extreme values are seen in the plot above: 2005-05-18, 2012-02-29, and 2012-10-04."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(df_london_fixes_daily_from_2016_on['Pd AM'])\n",
    "ax.grid()\n",
    "fig.set_size_inches(15, 5)\n",
    "plt.title(\"Palladium Spot Price (AM) - Initial Clean Data (part_2.csv.cleaned.csv) [2016+]\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price / USD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No extreme values seen in the plot above. The same data will still be run through the outlier isolation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(df_palladium_1['Pd AM'])\n",
    "ax.grid()\n",
    "fig.set_size_inches(15, 5)\n",
    "plt.title(\"Palladium Spot Price (AM) - Outliers Removed [1968-2015]\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price / USD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(df_palladium_2['Pd AM'])\n",
    "ax.grid()\n",
    "fig.set_size_inches(15, 5)\n",
    "plt.title(\"Palladium Spot Price (AM) - Outliers Removed [2016+]\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price / USD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
